import sqlite3
import openai
import ipywidgets as widgets
from IPython.display import display, clear_output, Image
import os
import io
from PIL import Image as PILImage
import pytesseract

# Asignar la ruta al ejecutable de Tesseract-OCR
# Asegúrate de reemplazar '<ruta_a_tu_tesseract.exe>' con la ruta correcta en tu sistema.
# Ejemplo para Windows: r'C:\Program Files\Tesseract-OCR\tesseract.exe'
# Si estás en Linux y has instalado Tesseract a través de apt o yum, probablemente no necesites hacer esto.
pytesseract.pytesseract.tesseract_cmd = r'<ruta_a_tu_tesseract.exe>'

# Inicializar la clave de API de OpenAI
openai.api_key = ''

# Conectar a la base de datos SQLite y crear la tabla si no existe
conn = sqlite3.connect('asistente_ai.db')
c = conn.cursor()
c.execute('''CREATE TABLE IF NOT EXISTS historial
             (id INTEGER PRIMARY KEY, solicitud TEXT, respuesta TEXT, fecha TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')
conn.commit()

def generar_respuesta_gpt3(texto_entrada):
    """Genera una respuesta utilizando OpenAI GPT-3."""
    try:
        respuesta = openai.ChatCompletion.create(
            model="gpt-3.5-turbo-1106",
            messages=[
                {"role": "system", "content": "Tienes una conversación con un asistente inteligente."},
                {"role": "user", "content": texto_entrada}
            ]
        )
        mensaje_respuesta = respuesta.choices[0].message['content']
        # Guardar en la base de datos SQLite
        c.execute("INSERT INTO historial (solicitud, respuesta) VALUES (?, ?)", (texto_entrada, mensaje_respuesta))
        conn.commit()
        return mensaje_respuesta
    except Exception as e:
        return f"Error: {e}"

def al_clicar(boton):
    """Maneja el evento de clic en el botón de enviar."""
    with area_respuesta:
        clear_output()
        print("Procesando tu solicitud...")
        respuesta_gpt3 = generar_respuesta_gpt3(texto_entrada.value)
        print(f"Respuesta: {respuesta_gpt3}")

def procesar_y_mostrar_imagen(cargador):
    """Procesa la imagen cargada usando OCR y muestra el texto extraído."""
    for nombre, archivo in cargador.value.items():
        imagen_bytes = io.BytesIO(archivo['content'])
        texto = pytesseract.image_to_string(PILImage.open(imagen_bytes))
        print(f"Texto extraído de {nombre}:")
        print(texto)
        display(PILImage.open(imagen_bytes))

# Widgets
texto_entrada = widgets.Text(placeholder='Escribe aquí tu pregunta', description='Pregunta:', disabled=False)
boton_enviar = widgets.Button(description='Enviar', button_style='', tooltip='Haz clic para enviar')
area_respuesta = widgets.Output()
cargador_imagenes = widgets.FileUpload(accept='image/*', multiple=False)
cargador_imagenes.observe(procesar_y_mostrar_imagen, names='value')

boton_enviar.on_click(al_clicar)

# Display widgets
display(widgets.VBox([texto_entrada, boton_enviar, area_respuesta, cargador_imagenes]))
